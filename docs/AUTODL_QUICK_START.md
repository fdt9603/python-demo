# Autodl A800 å¿«é€Ÿå¯åŠ¨æŒ‡å?

ä¸“ä¸ºAutodl A800 80GBæœåŠ¡å™¨ä¼˜åŒ–çš„å¿«é€Ÿå¯åŠ¨æŒ‡å—ã€?

## âœ?æœåŠ¡å™¨é…ç½®ç¡®è®?

ä½ çš„æœåŠ¡å™¨é…ç½®ï¼š
- âœ?GPU: A800 80GBï¼ˆæ»¡è¶³è¦æ±‚ï¼‰
- âœ?å†…å­˜: 100GBï¼ˆå……è¶³ï¼‰
- âœ?å­˜å‚¨: 200GBï¼ˆå……è¶³ï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ5æ­¥ï¼‰

### æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥ï¼ˆ1åˆ†é’Ÿï¼?

```bash
# è¿è¡Œå…¼å®¹æ€§æ£€æŸ?
python tools/check_autodl_compatibility.py

# æˆ–æ‰‹åŠ¨æ£€æŸ¥GPU
python -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0)}'); print(f'æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB')"
```

é¢„æœŸè¾“å‡ºï¼?
```
GPU: NVIDIA A800-SXM4-80GB (æˆ–ç±»ä¼?
æ˜¾å­˜: 80.0GB
```

### æ­¥éª¤2: å®‰è£…ä¾èµ–ï¼?-10åˆ†é’Ÿï¼?

```bash
# å®‰è£…æ‰€æœ‰ä¾èµ?
pip install -r requirements.txt

# å¦‚æœç½‘ç»œæ…¢ï¼Œä½¿ç”¨å›½å†…é•œåƒ
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# éªŒè¯å…³é”®ä¾èµ–
python -c "import torch; import transformers; import peft; print('âœ?æ ¸å¿ƒä¾èµ–å®‰è£…æˆåŠŸ')"
```

### æ­¥éª¤3: å‡†å¤‡æ•°æ®é›†ï¼ˆ10-30åˆ†é’Ÿï¼?

**æ–¹å¼A: ä½¿ç”¨DeepPCBæ•°æ®é›†ï¼ˆæ¨èï¼?*

```bash
# å¦‚æœå·²æœ‰DeepPCBæ•°æ®é›?
python tools/convert_deeppcb_dataset.py --deeppcb_dir /path/to/DeepPCB-master

# æ•°æ®é›†ä¼šè‡ªåŠ¨ä¿å­˜åœ?./data/pcb_defects/
```

**æ–¹å¼B: ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰**

```bash
# åˆ›å»ºç›®å½•
mkdir -p data/pcb_defects/images

# ç”Ÿæˆç¤ºä¾‹æ ‡ç­¾ï¼ˆéœ€è¦å…ˆæœ‰ä¸€äº›æµ‹è¯•å›¾åƒï¼‰
python -c "from data_loader import create_sample_labels_json; create_sample_labels_json('data/pcb_defects/labels.json', 'data/pcb_defects/images', num_samples=10)"
```

### æ­¥éª¤4: é…ç½®æ£€æŸ¥ï¼ˆ1åˆ†é’Ÿï¼?

ç¡®è®¤ `config.yaml` é…ç½®é€‚åˆA800ï¼?

```yaml
model:
  use_4bit: true  # âœ?å·²å¯ç”¨ï¼ŒèŠ‚çœæ˜¾å­˜
  device_map: "auto"  # âœ?è‡ªåŠ¨åˆ†é…

training:
  batch_size: 1  # âœ?ä¿å®ˆé…ç½®ï¼Œé€‚åˆA800
  gradient_accumulation_steps: 16  # âœ?æœ‰æ•ˆbatch size = 16
```

**æ— éœ€ä¿®æ”¹**ï¼Œé»˜è®¤é…ç½®å·²ä¼˜åŒ–ï¼?

### æ­¥éª¤5: å¼€å§‹è®­ç»?

```bash
# å¯åŠ¨è®­ç»ƒï¼ˆåå°è¿è¡Œï¼Œé¿å…SSHæ–­å¼€ï¼?
nohup python src/train/pcb_train.py \
    --data_dir ./data/pcb_defects \
    --output_dir ./checkpoints/pcb_checkpoints \
    > train.log 2>&1 &

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f train.log

# æˆ–è€…ä½¿ç”¨screenï¼ˆæ¨èï¼‰
screen -S pcb_train
python src/train/pcb_train.py --data_dir ./data/pcb_defects --output_dir ./checkpoints/pcb_checkpoints
# æŒ?Ctrl+A ç„¶å D åˆ†ç¦»ä¼šè¯
# é‡æ–°è¿æ¥: screen -r pcb_train
```

## ğŸ“Š èµ„æºç›‘æ§

### å®æ—¶ç›‘æ§GPU

```bash
# æ–¹æ³•1: ä½¿ç”¨watch
watch -n 1 nvidia-smi

# æ–¹æ³•2: ä½¿ç”¨gpustatï¼ˆå¦‚æœå·²å®‰è£…ï¼?
pip install gpustat
gpustat -i 1
```

### ç›‘æ§ç£ç›˜ç©ºé—´

```bash
# æŸ¥çœ‹ç£ç›˜ä½¿ç”¨
df -h .

# æŸ¥çœ‹å„ç›®å½•å¤§å°?
du -sh models/* checkpoints/* data/* 2>/dev/null
```

### ç›‘æ§å†…å­˜

```bash
# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
free -h

# æŸ¥çœ‹è¿›ç¨‹å†…å­˜
top -p $(pgrep -f pcb_train)
```

## âš?æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼ˆå¯é€‰ï¼‰

å¦‚æœä½ çš„A800æ˜¾å­˜å……è¶³ï¼ˆä½¿ç”?60GBï¼‰ï¼Œå¯ä»¥å°è¯•ï¼?

### 1. å¢åŠ batch sizeï¼ˆå¯é€‰ï¼‰

ç¼–è¾‘ `config.yaml`:

```yaml
training:
  batch_size: 2  # ä»?å¢åŠ åˆ?
  gradient_accumulation_steps: 8  # ä»?6å‡å°‘åˆ?ï¼ˆä¿æŒæœ‰æ•ˆbatch size=16ï¼?
```

### 2. ä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆå·²è‡ªåŠ¨å¯ç”¨ï¼?

ä»£ç ä¼šè‡ªåŠ¨æ£€æµ‹bf16æ”¯æŒï¼?
- A800æ”¯æŒbf16ï¼Œä¼šè‡ªåŠ¨å¯ç”¨
- æ— éœ€æ‰‹åŠ¨é…ç½®

### 3. å¤šGPUè®­ç»ƒï¼ˆå¦‚æœæœ‰å¤šå—A800ï¼?

```bash
# ä½¿ç”¨accelerateé…ç½®å¤šGPU
accelerate config

# ç„¶åä½¿ç”¨accelerateå¯åŠ¨
accelerate launch pcb_train.py --data_dir ./data/pcb_defects
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**ç°è±¡**: è®­ç»ƒæ—¶æŠ¥é”?`CUDA out of memory`

**è§£å†³**:
```yaml
# config.yaml ä¸­è°ƒæ•?
training:
  batch_size: 1  # ä¿æŒä¸?
  gradient_accumulation_steps: 32  # å¢åŠ åˆ?2ï¼ˆå¦‚æœåŸæ¥æ˜¯16ï¼?
```

### Q2: ç£ç›˜ç©ºé—´ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**è§£å†³**:
```bash
# 1. æ¸…ç†HuggingFaceç¼“å­˜ï¼ˆèŠ‚çœ~80GBï¼?
rm -rf ~/.cache/huggingface/hub/models--Qwen*

# 2. åˆ é™¤ä¸éœ€è¦çš„checkpoint
# åªä¿ç•™æœ€æ–°çš„å‡ ä¸ªcheckpoint

# 3. è®­ç»ƒå®Œæˆååˆ é™¤åŸºç¡€æ¨¡å‹ï¼ˆåªä¿ç•™é‡åŒ–æ¨¡å‹ï¼?
rm -rf models/qwen3-vl-pcb
```

### Q3: è®­ç»ƒä¸­æ–­æ€ä¹ˆåŠï¼Ÿ

**è§£å†³**:
```bash
# checkpointä¼šè‡ªåŠ¨ä¿å­˜ï¼Œå¯ä»¥ä»checkpointæ¢å¤
python src/train/pcb_train.py \
    --data_dir ./data/pcb_defects \
    --output_dir ./checkpoints/pcb_checkpoints \
    --resume_from_checkpoint ./checkpoints/pcb_checkpoints/checkpoint-500
```

### Q4: å¦‚ä½•æŸ¥çœ‹è®­ç»ƒè¿›åº¦ï¼?

```bash
# æŸ¥çœ‹æ—¥å¿—
tail -f train.log

# æˆ–è€…æŸ¥çœ‹æœ€æ–°checkpoint
ls -lh checkpoints/pcb_checkpoints/
```

## ğŸ“ˆ é¢„æœŸæ—¶é—´çº?

| é˜¶æ®µ | é¢„è®¡æ—¶é—´ | æ˜¾å­˜ä½¿ç”¨ | ç£ç›˜ä½¿ç”¨ |
|------|----------|----------|----------|
| æ•°æ®å‡†å¤‡ | 10-30åˆ†é’Ÿ | <1GB | ~5GB |
| æ¨¡å‹ä¸‹è½½ | 10-30åˆ†é’Ÿ | <1GB | ~80GB |
| è®­ç»ƒï¼?000æ­¥ï¼‰ | 2-3å¤?| ~35-50GB | +50GB |
| æ¨¡å‹åˆå¹¶ | 30-45åˆ†é’Ÿ | ~60GB | +60GB |
| AWQé‡åŒ– | 3-5å°æ—¶ | ~50GB | +25GB |

**æ€»è®¡**: çº?-4å¤©å®Œæˆå®Œæ•´æµç¨?

## âœ?éªŒè¯æ¸…å•

è¿è¡Œå‰ç¡®è®¤ï¼š

- [ ] GPUå¯ç”¨ï¼ˆ`nvidia-smi`æ˜¾ç¤ºA800ï¼?
- [ ] CUDAå¯ç”¨ï¼ˆ`python -c "import torch; print(torch.cuda.is_available())"`ï¼?
- [ ] ä¾èµ–å·²å®‰è£…ï¼ˆ`python tools/check_autodl_compatibility.py`ï¼?
- [ ] æ•°æ®é›†å·²å‡†å¤‡ï¼ˆ`ls data/pcb_defects/labels.json`ï¼?
- [ ] ç£ç›˜ç©ºé—´å……è¶³ï¼ˆ`df -h .`æ˜¾ç¤ºè‡³å°‘150GBå¯ç”¨ï¼?
- [ ] config.yamlé…ç½®æ­£ç¡®ï¼ˆ`use_4bit: true`ï¼?

## ğŸ¯ ä¸‹ä¸€æ­?

è®­ç»ƒå®Œæˆåï¼š

1. **åˆå¹¶æ¨¡å‹**: `python src/train/merge_model.py ...`
2. **é‡åŒ–æ¨¡å‹**: `python src/train/quantize_model.py ...`
3. **éªŒè¯æ¨¡å‹**: `python src/inference/validation_pcb.py ...`
4. **éƒ¨ç½²æœåŠ¡**: `python src/inference/mllm_api.py ...`

è¯¦ç»†æ­¥éª¤è¯·å‚è€?[QUICKSTART.md](QUICKSTART.md)

---

**æç¤º**: Autodl A800å®Œå…¨å…¼å®¹ï¼Œæ— éœ€ä»»ä½•ä»£ç ä¿®æ”¹å³å¯è¿è¡Œï¼?

