#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Autodl A800å…¼å®¹æ€§æ£€æŸ¥è„šæœ¬
æ£€æŸ¥é¡¹ç›®æ˜¯å¦å¯ä»¥åœ¨Autodl A800 80GBæœåŠ¡å™¨ä¸Šè¿è¡Œ
"""
import os
import sys
import subprocess
from pathlib import Path


def check_gpu():
    """æ£€æŸ¥GPUä¿¡æ¯"""
    print("=" * 60)
    print("ğŸ” æ£€æŸ¥GPUä¿¡æ¯...")
    print("=" * 60)
    
    try:
        import torch
        if not torch.cuda.is_available():
            print("âŒ CUDAä¸å¯ç”¨")
            return False
        
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB
        
        print(f"âœ… GPUå‹å·: {gpu_name}")
        print(f"âœ… æ˜¾å­˜å¤§å°: {gpu_memory:.1f} GB")
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³è¦æ±‚ï¼ˆ>=80GBï¼‰
        if gpu_memory >= 80:
            print(f"âœ… GPUæ˜¾å­˜æ»¡è¶³è¦æ±‚ï¼ˆ>=80GBï¼‰")
            return True
        elif gpu_memory >= 40:
            print(f"âš ï¸  GPUæ˜¾å­˜ {gpu_memory:.1f}GBï¼Œå¯èƒ½è¶³å¤Ÿï¼ˆæ¨è80GB+ï¼‰")
            return True
        else:
            print(f"âŒ GPUæ˜¾å­˜ä¸è¶³: {gpu_memory:.1f}GBï¼ˆéœ€è¦>=80GBï¼‰")
            return False
            
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return False


def check_cuda_version():
    """æ£€æŸ¥CUDAç‰ˆæœ¬"""
    print("\n" + "=" * 60)
    print("ğŸ” æ£€æŸ¥CUDAç‰ˆæœ¬...")
    print("=" * 60)
    
    try:
        import torch
        cuda_version = torch.version.cuda
        if cuda_version:
            print(f"âœ… CUDAç‰ˆæœ¬: {cuda_version}")
            # æ£€æŸ¥ç‰ˆæœ¬æ˜¯å¦>=11.8
            major, minor = map(int, cuda_version.split('.')[:2])
            if major > 11 or (major == 11 and minor >= 8):
                print("âœ… CUDAç‰ˆæœ¬æ»¡è¶³è¦æ±‚ï¼ˆ>=11.8ï¼‰")
                return True
            else:
                print(f"âš ï¸  CUDAç‰ˆæœ¬ {cuda_version} å¯èƒ½è¾ƒæ—§ï¼ˆæ¨è11.8+ï¼‰")
                return True  # ä»ç„¶å¯ä»¥è¿è¡Œ
        else:
            print("âš ï¸  æ— æ³•è·å–CUDAç‰ˆæœ¬ï¼ˆå¯èƒ½ä½¿ç”¨CPUç‰ˆæœ¬ï¼‰")
            return False
    except Exception as e:
        print(f"âš ï¸  æ£€æŸ¥CUDAç‰ˆæœ¬æ—¶å‡ºé”™: {e}")
        return False


def check_disk_space():
    """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
    print("\n" + "=" * 60)
    print("ğŸ” æ£€æŸ¥ç£ç›˜ç©ºé—´...")
    print("=" * 60)
    
    try:
        import shutil
        total, used, free = shutil.disk_usage('.')
        
        total_gb = total / (1024**3)
        used_gb = used / (1024**3)
        free_gb = free / (1024**3)
        
        print(f"æ€»ç©ºé—´: {total_gb:.1f} GB")
        print(f"å·²ä½¿ç”¨: {used_gb:.1f} GB")
        print(f"å¯ç”¨ç©ºé—´: {free_gb:.1f} GB")
        
        # ä¼°ç®—éœ€è¦çš„ç©ºé—´
        required_space = 200  # GB
        model_space = 25  # é‡åŒ–æ¨¡å‹
        checkpoint_space = 50  # è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆå¤šä¸ªï¼‰
        dataset_space = 5  # æ•°æ®é›†
        cache_space = 80  # HuggingFaceç¼“å­˜ï¼ˆåŸºç¡€æ¨¡å‹ï¼‰
        total_required = model_space + checkpoint_space + dataset_space + cache_space
        
        print(f"\nğŸ“Š ç©ºé—´éœ€æ±‚ä¼°ç®—:")
        print(f"  - é‡åŒ–æ¨¡å‹: ~{model_space}GB")
        print(f"  - è®­ç»ƒæ£€æŸ¥ç‚¹: ~{checkpoint_space}GB")
        print(f"  - æ•°æ®é›†: ~{dataset_space}GB")
        print(f"  - HuggingFaceç¼“å­˜: ~{cache_space}GB")
        print(f"  - æ€»è®¡éœ€æ±‚: ~{total_required}GB")
        
        if free_gb >= total_required:
            print(f"âœ… å¯ç”¨ç©ºé—´å……è¶³ï¼ˆéœ€è¦{total_required}GBï¼Œå¯ç”¨{free_gb:.1f}GBï¼‰")
            return True
        elif free_gb >= required_space:
            print(f"âš ï¸  å¯ç”¨ç©ºé—´å¯èƒ½ä¸è¶³ï¼ˆéœ€è¦{total_required}GBï¼Œå¯ç”¨{free_gb:.1f}GBï¼‰")
            print("   å»ºè®®æ¸…ç†ç©ºé—´æˆ–ä½¿ç”¨å¤–éƒ¨å­˜å‚¨")
            return True
        else:
            print(f"âŒ å¯ç”¨ç©ºé—´ä¸è¶³ï¼ˆéœ€è¦{total_required}GBï¼Œå¯ç”¨{free_gb:.1f}GBï¼‰")
            return False
            
    except Exception as e:
        print(f"âš ï¸  æ£€æŸ¥ç£ç›˜ç©ºé—´æ—¶å‡ºé”™: {e}")
        return True  # å‡è®¾å¯ä»¥


def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    print("\n" + "=" * 60)
    print("ğŸ” æ£€æŸ¥Pythonç‰ˆæœ¬...")
    print("=" * 60)
    
    version = sys.version_info
    print(f"Pythonç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")
    
    if version >= (3, 8):
        print("âœ… Pythonç‰ˆæœ¬æ»¡è¶³è¦æ±‚ï¼ˆ>=3.8ï¼‰")
        return True
    else:
        print("âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼ˆéœ€è¦>=3.8ï¼‰")
        return False


def check_dependencies():
    """æ£€æŸ¥å…³é”®ä¾èµ–"""
    print("\n" + "=" * 60)
    print("ğŸ” æ£€æŸ¥å…³é”®ä¾èµ–...")
    print("=" * 60)
    
    dependencies = {
        'torch': 'PyTorch',
        'transformers': 'Transformers',
        'peft': 'PEFT (LoRA)',
        'autoawq': 'AutoAWQ (é‡åŒ–)',
        'accelerate': 'Accelerate',
    }
    
    all_ok = True
    for module, name in dependencies.items():
        try:
            mod = __import__(module)
            version = getattr(mod, '__version__', 'unknown')
            print(f"âœ… {name}: {version}")
        except ImportError:
            print(f"âŒ {name}: æœªå®‰è£…")
            all_ok = False
    
    return all_ok


def check_model_config():
    """æ£€æŸ¥æ¨¡å‹é…ç½®å…¼å®¹æ€§"""
    print("\n" + "=" * 60)
    print("ğŸ” æ£€æŸ¥æ¨¡å‹é…ç½®...")
    print("=" * 60)
    
    try:
        try:
            import yaml
        except ImportError:
            try:
                import ruamel.yaml as yaml
            except ImportError:
                print("âš ï¸  æ— æ³•å¯¼å…¥yamlåº“ï¼Œè·³è¿‡é…ç½®æ£€æŸ¥")
                return True
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # æ£€æŸ¥4-bité…ç½®ï¼ˆå¯¹A800å¾ˆé‡è¦ï¼‰
        use_4bit = config.get('model', {}).get('use_4bit', True)
        if use_4bit:
            print("âœ… å·²å¯ç”¨4-bité‡åŒ–ï¼ˆèŠ‚çœæ˜¾å­˜ï¼Œé€‚åˆA800ï¼‰")
        else:
            print("âš ï¸  æœªå¯ç”¨4-bité‡åŒ–ï¼ˆå¯èƒ½éœ€è¦æ›´å¤šæ˜¾å­˜ï¼‰")
        
        # æ£€æŸ¥batch size
        batch_size = config.get('training', {}).get('batch_size', 1)
        grad_accum = config.get('training', {}).get('gradient_accumulation_steps', 16)
        effective_batch = batch_size * grad_accum
        print(f"âœ… æ‰¹æ¬¡å¤§å°: {batch_size} Ã— {grad_accum} = {effective_batch}ï¼ˆæœ‰æ•ˆæ‰¹æ¬¡ï¼‰")
        
        # æ£€æŸ¥device_map
        device_map = config.get('model', {}).get('device_map', 'auto')
        print(f"âœ… è®¾å¤‡æ˜ å°„: {device_map}")
        
        return True
        
    except Exception as e:
        print(f"âš ï¸  æ£€æŸ¥é…ç½®æ—¶å‡ºé”™: {e}")
        return True


def estimate_memory_usage():
    """ä¼°ç®—å†…å­˜ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ğŸ“Š å†…å­˜ä½¿ç”¨ä¼°ç®—...")
    print("=" * 60)
    
    print("è®­ç»ƒé˜¶æ®µï¼ˆä½¿ç”¨4-bité‡åŒ–ï¼‰:")
    print("  - æ¨¡å‹ï¼ˆ4-bitï¼‰: ~20-25GB æ˜¾å­˜")
    print("  - ä¼˜åŒ–å™¨çŠ¶æ€: ~5-10GB æ˜¾å­˜")
    print("  - æ¿€æ´»å€¼: ~5-10GB æ˜¾å­˜")
    print("  - æ€»è®¡: ~30-45GB æ˜¾å­˜ï¼ˆA800 80GBå……è¶³ï¼‰")
    
    print("\næ¨ç†é˜¶æ®µï¼ˆé‡åŒ–æ¨¡å‹ï¼‰:")
    print("  - é‡åŒ–æ¨¡å‹: ~20-25GB æ˜¾å­˜")
    print("  - æ¿€æ´»å€¼: ~2-5GB æ˜¾å­˜")
    print("  - æ€»è®¡: ~25-30GB æ˜¾å­˜ï¼ˆA800 80GBå……è¶³ï¼‰")
    
    print("\nç³»ç»Ÿå†…å­˜ï¼ˆRAMï¼‰:")
    print("  - æ•°æ®åŠ è½½: ~5-10GB")
    print("  - Pythonè¿›ç¨‹: ~2-5GB")
    print("  - æ€»è®¡: ~10-20GBï¼ˆ100GB RAMå……è¶³ï¼‰")


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("ğŸš€ Autodl A800 å…¼å®¹æ€§æ£€æŸ¥")
    print("=" * 60)
    print("\næœåŠ¡å™¨é…ç½®:")
    print("  - GPU: A800 80GB")
    print("  - å†…å­˜: 100GB")
    print("  - å­˜å‚¨: 200GB")
    print("=" * 60 + "\n")
    
    checks = []
    
    # æ‰§è¡Œå„é¡¹æ£€æŸ¥
    checks.append(("GPUæ£€æŸ¥", check_gpu()))
    checks.append(("CUDAç‰ˆæœ¬", check_cuda_version()))
    checks.append(("Pythonç‰ˆæœ¬", check_python_version()))
    checks.append(("ç£ç›˜ç©ºé—´", check_disk_space()))
    checks.append(("ä¾èµ–æ£€æŸ¥", check_dependencies()))
    checks.append(("é…ç½®æ£€æŸ¥", check_model_config()))
    
    # å†…å­˜ä¼°ç®—
    estimate_memory_usage()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ£€æŸ¥æ€»ç»“")
    print("=" * 60)
    
    all_passed = True
    for name, result in checks:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
        if not result:
            all_passed = False
    
    print("\n" + "=" * 60)
    if all_passed:
        print("âœ… å…¼å®¹æ€§æ£€æŸ¥é€šè¿‡ï¼é¡¹ç›®å¯ä»¥åœ¨Autodl A800ä¸Šè¿è¡Œ")
        print("\nğŸ’¡ å»ºè®®:")
        print("  1. ç¡®ä¿ä½¿ç”¨4-bité‡åŒ–ï¼ˆconfig.yamlä¸­å·²é…ç½®ï¼‰")
        print("  2. è®­ç»ƒæ—¶ç›‘æ§æ˜¾å­˜ä½¿ç”¨: watch -n 1 nvidia-smi")
        print("  3. å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œå¯ä»¥å‡å°batch_sizeæˆ–gradient_accumulation_steps")
        print("  4. æ³¨æ„æ¸…ç†HuggingFaceç¼“å­˜ä»¥èŠ‚çœç©ºé—´")
    else:
        print("âŒ å­˜åœ¨å…¼å®¹æ€§é—®é¢˜ï¼Œè¯·æ ¹æ®ä¸Šè¿°æ£€æŸ¥ç»“æœè§£å†³")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    main()

